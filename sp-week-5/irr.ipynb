{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c711ed4-6951-481d-81e8-de76b4344d5a",
   "metadata": {},
   "source": [
    "# Annotation Inter-Rater Reliability\n",
    "\n",
    "We are creating a span categorization model which means we have two forms of \"data\" for each annotation.\n",
    "\n",
    "* Whether there was an annotation at all\n",
    "* The start and stop of eac annotation\n",
    "\n",
    "## \"Any Annotation at All\"\n",
    "\n",
    "This can be turned into a binary annotation metric and as such we can use more standard IRR metrics.\n",
    "In this case we will be using [Fleiss Kappa](https://en.wikipedia.org/wiki/Fleiss%27_kappa).\n",
    "\n",
    "## \"Same Label on Span\"\n",
    "\n",
    "Extract the annotation label from the span and use Fleiss Kappa on the retrived data.\n",
    "\n",
    "## \"Number of Spans within Example\"\n",
    "\n",
    "Extract the number of spans from each example and use Fleiss Kappa on the retrieved data.\n",
    "\n",
    "## \"Agreement on Span Positioning\"\n",
    "\n",
    "In each case that annotators agreed a span was present within the example, compare the span start and stop.\n",
    "The most common task in which start and stop points are compared and evaluated against others is in \"text segmentation\".\n",
    "As such, we are using a text segmentation evaluation metic called [\"boundary agreement\"](https://segeval.readthedocs.io/en/latest/api/?highlight=agreement#inter-coder-agreement-coefficients)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f17aa9-57b1-4087-871b-f862e0a65799",
   "metadata": {},
   "source": [
    "## Basic Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aa34582-6bb0-4163-b530-8b17309fa88d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((112, 10),\n",
       " Index(['text', 'meta', '_input_hash', '_task_hash', 'tokens', '_view_id',\n",
       "        'answer', '_timestamp', 'spans', 'annotator'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import and combine all data\n",
    "import pandas as pd\n",
    "\n",
    "ANNOTATOR_TO_FILE_LUT = {\n",
    "    \"angel\": \"annotations-angel-round-3.jsonl\",\n",
    "    \"sarah\": \"annotations-sarah-round-3.jsonl\",\n",
    "    \"kelly\": \"annotations-kelly-round-3.jsonl\",\n",
    "    \"leo\": \"annotations-leo-round-3.jsonl\",\n",
    "}\n",
    "annotation_dfs = []\n",
    "for annotator, filename in ANNOTATOR_TO_FILE_LUT.items():\n",
    "    with open(filename) as open_f:\n",
    "        this_annotator_df = pd.read_json(open_f, lines=True).sort_values(by=[\"text\"])\n",
    "        this_annotator_df[\"annotator\"] = annotator\n",
    "        annotation_dfs.append(this_annotator_df)\n",
    "\n",
    "annotations = pd.concat(annotation_dfs, ignore_index=True)\n",
    "annotations.shape, annotations.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb1d155-b31b-44c6-bd58-e2d545e958fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>spans</th>\n",
       "      <th>annotator</th>\n",
       "      <th>muni</th>\n",
       "      <th>session_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down morning. I'm chair of tree pack. It's dis...</td>\n",
       "      <td>ignore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angel</td>\n",
       "      <td>seattle</td>\n",
       "      <td>6c40d8abf3c9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efz Ning, members of the Oakland City Council,...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 58, 'end': 132, 'token_start': 13, ...</td>\n",
       "      <td>angel</td>\n",
       "      <td>oakland</td>\n",
       "      <td>c658b9361f53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon, Council. Thank you for the cha...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 71, 'end': 157, 'token_start': 16, ...</td>\n",
       "      <td>angel</td>\n",
       "      <td>seattle</td>\n",
       "      <td>c6bbc7ceec24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon, Greg McConnell, I'm here on be...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 16, 'end': 72, 'token_start': 3, 't...</td>\n",
       "      <td>angel</td>\n",
       "      <td>oakland</td>\n",
       "      <td>d83519594701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good afternoon, members of committee, my name ...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 49, 'end': 99, 'token_start': 10, '...</td>\n",
       "      <td>angel</td>\n",
       "      <td>oakland</td>\n",
       "      <td>b7cdf3723be0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  answer  \\\n",
       "0  Down morning. I'm chair of tree pack. It's dis...  ignore   \n",
       "1  Efz Ning, members of the Oakland City Council,...  accept   \n",
       "2  Good afternoon, Council. Thank you for the cha...  accept   \n",
       "3  Good afternoon, Greg McConnell, I'm here on be...  accept   \n",
       "4  Good afternoon, members of committee, my name ...  accept   \n",
       "\n",
       "                                               spans annotator     muni  \\\n",
       "0                                                NaN     angel  seattle   \n",
       "1  [{'start': 58, 'end': 132, 'token_start': 13, ...     angel  oakland   \n",
       "2  [{'start': 71, 'end': 157, 'token_start': 16, ...     angel  seattle   \n",
       "3  [{'start': 16, 'end': 72, 'token_start': 3, 't...     angel  oakland   \n",
       "4  [{'start': 49, 'end': 99, 'token_start': 10, '...     angel  oakland   \n",
       "\n",
       "     session_id  \n",
       "0  6c40d8abf3c9  \n",
       "1  c658b9361f53  \n",
       "2  c6bbc7ceec24  \n",
       "3  d83519594701  \n",
       "4  b7cdf3723be0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpack meta\n",
    "unpackaged_json = pd.json_normalize(annotations[\"meta\"])\n",
    "annotations[\"muni\"] = unpackaged_json[\"muni\"]\n",
    "annotations[\"session_id\"] = unpackaged_json[\"session_id\"]\n",
    "\n",
    "# Drop columns\n",
    "annotations = annotations[[\"text\", \"answer\", \"spans\", \"annotator\", \"muni\", \"session_id\"]]\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b2663d5-eaf2-4b66-a73f-cb1dc0fdf806",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def print_annotator_diffs(data, label_col, annotator_col=\"annotator\", link_col=\"text\"):\n",
    "    # Get just annotation series\n",
    "    annotations: Dict[str, pd.Series] = {}\n",
    "    link_series: Optional[pd.Series] = None\n",
    "    \n",
    "    # Iter annotators\n",
    "    for annotator_label in data[annotator_col].unique():\n",
    "        # Just their subset\n",
    "        annotator_subset = data.loc[\n",
    "            data[annotator_col] == annotator_label\n",
    "        ].reset_index(drop=True)\n",
    "        \n",
    "        # Get their labels\n",
    "        annotations[annotator_label] = annotator_subset[label_col]\n",
    "        if link_series is None:\n",
    "            link_series = annotator_subset[link_col]\n",
    "\n",
    "    # Each annotator column values as columns\n",
    "    annotations_df = pd.DataFrame(\n",
    "        {\n",
    "            link_col: link_series,\n",
    "            **annotations,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    # Get all annotator pairs\n",
    "    annotator_pairs = combinations(data[annotator_col].unique(), 2)\n",
    "    # Construct pairwise diffs\n",
    "    diffs = []\n",
    "    for anno_one, anno_two in annotator_pairs:\n",
    "        diffs.append(annotations_df.loc[annotations_df[anno_one] != annotations_df[anno_two]])\n",
    "    diff_df = pd.concat(diffs)\n",
    "    diff_df = diff_df.drop_duplicates(subset=[link_col]).reset_index(drop=True)\n",
    "    print(f\"Differing labels for '{label_col}'\")\n",
    "    print(diff_df)\n",
    "    print()\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0f29f-e375-4552-b460-c5a883ee59e8",
   "metadata": {},
   "source": [
    "## Fleiss Kappa for \"Any Annotation at All\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e91eb6-a43f-461c-ac2f-5c5a2fe3ac75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differing labels for 'answer'\n",
      "                                                text   angel   sarah   kelly  \\\n",
      "0  Good morning, Pete her. Good morning. I'm in d...  ignore  accept  ignore   \n",
      "1  So Doug and Andrew if you are out there, call ...  accept  ignore  accept   \n",
      "\n",
      "      leo  \n",
      "0  ignore  \n",
      "1  accept  \n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9181286549707602, 'Almost perfect agreement')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.inter_rater import aggregate_raters, fleiss_kappa\n",
    "\n",
    "def _interpreted_score(v: float) -> str:\n",
    "        if v < 0:\n",
    "            return \"No agreement\"\n",
    "        if v < 0.2:\n",
    "            return \"Poor agreement\"\n",
    "        if v >= 0.2 and v < 0.4:\n",
    "            return \"Fair agreement\"\n",
    "        if v >= 0.4 and v < 0.6:\n",
    "            return \"Moderate agreement\"\n",
    "        if v >= 0.6 and v < 0.8:\n",
    "            return \"Substantial agreement\"\n",
    "        return \"Almost perfect agreement\"\n",
    "\n",
    "# Create new dataframe where rows are the answers and columns are each annotator\n",
    "annotator_answers = {}\n",
    "for annotator in annotations.annotator.unique():\n",
    "    this_annotator_data = annotations[annotations.annotator == annotator]\n",
    "    annotator_answers[annotator] = this_annotator_data[\"answer\"].reset_index(drop=True)\n",
    "\n",
    "annotator_answers = pd.DataFrame(annotator_answers)\n",
    "\n",
    "# Aggregate annotator answers\n",
    "agg_raters, _ = aggregate_raters(annotator_answers)\n",
    "\n",
    "# Compute statistical fleiss kappa\n",
    "any_annotation_at_all_score = fleiss_kappa(agg_raters)\n",
    "\n",
    "# Interpret and print\n",
    "print_annotator_diffs(annotations, \"answer\")\n",
    "any_annotation_at_all_score, _interpreted_score(any_annotation_at_all_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6c102-6ac1-4be1-a5af-751003fd5968",
   "metadata": {},
   "source": [
    "## Data Prep for Span Evaluation\n",
    "\n",
    "Note: we are constructing segmentation strings from the span start and stop using the [NLTK segmentation string standard](https://segeval.readthedocs.io/en/latest/api/?highlight=agreement#segeval.convert_nltk_to_masses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e10a0c73-2de7-4c84-b323-0810be9bd208",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>answer</th>\n",
       "      <th>spans</th>\n",
       "      <th>annotator</th>\n",
       "      <th>muni</th>\n",
       "      <th>session_id</th>\n",
       "      <th>n_spans</th>\n",
       "      <th>span_label</th>\n",
       "      <th>span_segmentation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down morning. I'm chair of tree pack. It's dis...</td>\n",
       "      <td>ignore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>angel</td>\n",
       "      <td>seattle</td>\n",
       "      <td>6c40d8abf3c9</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>(423,)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Efz Ning, members of the Oakland City Council,...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 58, 'end': 132, 'token_start': 13, ...</td>\n",
       "      <td>angel</td>\n",
       "      <td>oakland</td>\n",
       "      <td>c658b9361f53</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSON-AFFLIATED-WITH-ORG</td>\n",
       "      <td>(59, 74, 732)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good afternoon, Council. Thank you for the cha...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 71, 'end': 157, 'token_start': 16, ...</td>\n",
       "      <td>angel</td>\n",
       "      <td>seattle</td>\n",
       "      <td>c6bbc7ceec24</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSON-AFFLIATED-WITH-ORG</td>\n",
       "      <td>(72, 86, 246)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good afternoon, Greg McConnell, I'm here on be...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 16, 'end': 72, 'token_start': 3, 't...</td>\n",
       "      <td>angel</td>\n",
       "      <td>oakland</td>\n",
       "      <td>d83519594701</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>(17, 56, 1389)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good afternoon, members of committee, my name ...</td>\n",
       "      <td>accept</td>\n",
       "      <td>[{'start': 49, 'end': 99, 'token_start': 10, '...</td>\n",
       "      <td>angel</td>\n",
       "      <td>oakland</td>\n",
       "      <td>b7cdf3723be0</td>\n",
       "      <td>1</td>\n",
       "      <td>PERSON-AFFLIATED-WITH-ORG</td>\n",
       "      <td>(50, 50, 1471)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  answer  \\\n",
       "0  Down morning. I'm chair of tree pack. It's dis...  ignore   \n",
       "1  Efz Ning, members of the Oakland City Council,...  accept   \n",
       "2  Good afternoon, Council. Thank you for the cha...  accept   \n",
       "3  Good afternoon, Greg McConnell, I'm here on be...  accept   \n",
       "4  Good afternoon, members of committee, my name ...  accept   \n",
       "\n",
       "                                               spans annotator     muni  \\\n",
       "0                                                NaN     angel  seattle   \n",
       "1  [{'start': 58, 'end': 132, 'token_start': 13, ...     angel  oakland   \n",
       "2  [{'start': 71, 'end': 157, 'token_start': 16, ...     angel  seattle   \n",
       "3  [{'start': 16, 'end': 72, 'token_start': 3, 't...     angel  oakland   \n",
       "4  [{'start': 49, 'end': 99, 'token_start': 10, '...     angel  oakland   \n",
       "\n",
       "     session_id  n_spans                 span_label span_segmentation  \n",
       "0  6c40d8abf3c9        0                       None            (423,)  \n",
       "1  c658b9361f53        1  PERSON-AFFLIATED-WITH-ORG     (59, 74, 732)  \n",
       "2  c6bbc7ceec24        1  PERSON-AFFLIATED-WITH-ORG     (72, 86, 246)  \n",
       "3  d83519594701        1                     PERSON    (17, 56, 1389)  \n",
       "4  b7cdf3723be0        1  PERSON-AFFLIATED-WITH-ORG    (50, 50, 1471)  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import segeval\n",
    "\n",
    "# For each row in the dataset, unpack the span content to the larger dataframe\n",
    "def unpack_span_details(row):\n",
    "    if isinstance(row[\"spans\"], list):\n",
    "        row[\"n_spans\"] = len(row[\"spans\"])\n",
    "        row[\"span_label\"] = \",\".join([span[\"label\"] for span in row[\"spans\"]])\n",
    "        start_and_stop_indices = [\n",
    "            *[span[\"start\"] for span in row[\"spans\"]],\n",
    "            *[span[\"end\"] for span in row[\"spans\"]],\n",
    "        ]\n",
    "        row[\"span_segmentation\"] = \"\".join([\"1\" if i in start_and_stop_indices else \"0\" for i in range(len(row[\"text\"]))])\n",
    "    else:\n",
    "        row[\"n_spans\"] = 0\n",
    "        row[\"span_label\"] = \"None\"\n",
    "        row[\"span_segmentation\"] = \"\".join([\"0\" for i in range(len(row[\"text\"]))])\n",
    "        \n",
    "    if len(row[\"span_label\"]) <= 3:\n",
    "        row[\"n_spans\"] = 0\n",
    "        row[\"span_label\"] = \"None\"\n",
    "        row[\"span_segmentation\"] = \"\".join([\"0\" for i in range(len(row[\"text\"]))])\n",
    "    \n",
    "    # Convert to segeval masses\n",
    "    row[\"span_segmentation\"] = segeval.convert_nltk_to_masses(row[\"span_segmentation\"])\n",
    "    \n",
    "    return row\n",
    "\n",
    "annotations = annotations.apply(unpack_span_details, axis=1)\n",
    "annotations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e40122-5c14-4c94-a589-fd219fdd0c01",
   "metadata": {},
   "source": [
    "## Fleiss Kappa for \"Same Label on Span\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dc89881-44ca-4fe3-9067-e3070722c8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differing labels for 'span_label'\n",
      "                                                text  \\\n",
      "0  Good morning, Pete her. Good morning. I'm in d...   \n",
      "1  Good morning. I am Madison, resident of distri...   \n",
      "2  So Doug and Andrew if you are out there, call ...   \n",
      "3  Good afternoon, Greg McConnell, I'm here on be...   \n",
      "\n",
      "                       angel   sarah                      kelly  \\\n",
      "0                       None  PERSON                       None   \n",
      "1  PERSON-AFFLIATED-WITH-ORG  PERSON  PERSON-AFFLIATED-WITH-ORG   \n",
      "2                     PERSON    None                     PERSON   \n",
      "3                     PERSON  PERSON                     PERSON   \n",
      "\n",
      "                         leo  \n",
      "0                       None  \n",
      "1  PERSON-AFFLIATED-WITH-ORG  \n",
      "2                     PERSON  \n",
      "3  PERSON-AFFLIATED-WITH-ORG  \n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8914728682170543, 'Almost perfect agreement')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe where rows are the answers and columns are each annotator\n",
    "annotator_answers = {}\n",
    "for annotator in annotations.annotator.unique():\n",
    "    this_annotator_data = annotations[annotations.annotator == annotator]\n",
    "    annotator_answers[annotator] = this_annotator_data[\"span_label\"].reset_index(drop=True)\n",
    "\n",
    "annotator_answers = pd.DataFrame(annotator_answers)\n",
    "\n",
    "# Aggregate annotator answers\n",
    "agg_raters, _ = aggregate_raters(annotator_answers)\n",
    "\n",
    "# Compute statistical fleiss kappa\n",
    "any_annotation_at_all_score = fleiss_kappa(agg_raters)\n",
    "\n",
    "# Interpret and print\n",
    "print_annotator_diffs(annotations, \"span_label\")\n",
    "any_annotation_at_all_score, _interpreted_score(any_annotation_at_all_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d657689-5821-4f7b-945d-e8aaa36f3ed8",
   "metadata": {},
   "source": [
    "## Fleiss Kappa for \"Number of Spans within Example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26d1c583-0b7e-4bce-b4e8-6ebdfe980a50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differing labels for 'n_spans'\n",
      "                                                text  angel  sarah  kelly  leo\n",
      "0  Good morning, Pete her. Good morning. I'm in d...      0      1      0    0\n",
      "1  So Doug and Andrew if you are out there, call ...      1      0      1    1\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9360730593607308, 'Almost perfect agreement')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new dataframe where rows are the answers and columns are each annotator\n",
    "annotator_answers = {}\n",
    "for annotator in annotations.annotator.unique():\n",
    "    this_annotator_data = annotations[annotations.annotator == annotator]\n",
    "    annotator_answers[annotator] = this_annotator_data[\"n_spans\"].reset_index(drop=True)\n",
    "\n",
    "annotator_answers = pd.DataFrame(annotator_answers)\n",
    "\n",
    "# Aggregate annotator answers\n",
    "agg_raters, _ = aggregate_raters(annotator_answers)\n",
    "\n",
    "# Compute statistical fleiss kappa\n",
    "any_annotation_at_all_score = fleiss_kappa(agg_raters)\n",
    "\n",
    "# Interpret and print\n",
    "print_annotator_diffs(annotations, \"n_spans\")\n",
    "any_annotation_at_all_score, _interpreted_score(any_annotation_at_all_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a177a6-8d46-437f-a2fa-d49337d4f692",
   "metadata": {},
   "source": [
    "## Boundary Similarity for \"Agreement on Span Positioning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d046340-bad3-46f7-a1a8-e107d8bf475f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m         item_masses[item_index][annotator] \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan_segmentation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Compute boundary similarity\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43msegeval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactual_agreement_linear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_masses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/sig-cdp/lib/python3.9/site-packages/segeval/agreement/__init__.py:180\u001b[0m, in \u001b[0;36mactual_agreement_linear\u001b[0;34m(dataset, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mactual_agreement_linear\u001b[39m(dataset, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__fnc_metric__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__actual_agreement_linear__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/sig-cdp/lib/python3.9/site-packages/segeval/agreement/__init__.py:30\u001b[0m, in \u001b[0;36m__fnc_metric__\u001b[0;34m(fnc_metric, dataset, **kwargs)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundary_format\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     29\u001b[0m     metric_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboundary_format\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mboundary_format\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfnc_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/sig-cdp/lib/python3.9/site-packages/segeval/agreement/__init__.py:157\u001b[0m, in \u001b[0;36m__actual_agreement_linear__\u001b[0;34m(dataset, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m segs_b \u001b[38;5;241m=\u001b[39m dataset[item][coders[n]]\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# Compute similarity\u001b[39;00m\n\u001b[1;32m    156\u001b[0m numerator, denominator \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m--> 157\u001b[0m     \u001b[43mfnc_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegs_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegs_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Obtain necessary values\u001b[39;00m\n\u001b[1;32m    159\u001b[0m pbs \u001b[38;5;241m=\u001b[39m __potential_boundaries__(segs_a, segs_b, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmetric_kwargs)\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/sig-cdp/lib/python3.9/site-packages/segeval/similarity/boundary.py:44\u001b[0m, in \u001b[0;36mboundary_similarity\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mboundary_similarity\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    Boundary Similarity (B).\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m__fnc_metric__\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__boundary_similarity__\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mSIMILARITY_METRIC_DEFAULTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/sig-cdp/lib/python3.9/site-packages/segeval/util/__init__.py:81\u001b[0m, in \u001b[0;36m__fnc_metric__\u001b[0;34m(fnc_metric, args, kwargs, kw_defaults)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;66;03m# Compare a single pair of segmentations\u001b[39;00m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m metric_kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpermuted\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfnc_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypothesis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Except if insufficient arguments supplied\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m SegmentationMetricError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncorrect arguments specified; expected 1 or 2, obtained \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of value: \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(args)), \u001b[38;5;28mstr\u001b[39m(args)))\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/sig-cdp/lib/python3.9/site-packages/segeval/similarity/boundary.py:21\u001b[0m, in \u001b[0;36m__boundary_similarity__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m one_minus \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mone_minus\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m statistics \u001b[38;5;241m=\u001b[39m \u001b[43m__boundary_statistics__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmetric_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m additions \u001b[38;5;241m=\u001b[39m statistics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madditions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     23\u001b[0m substitutions \u001b[38;5;241m=\u001b[39m statistics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubstitutions\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/sig-cdp/lib/python3.9/site-packages/segeval/similarity/__init__.py:65\u001b[0m, in \u001b[0;36m__boundary_statistics__\u001b[0;34m(segs_a, segs_b, boundary_types, boundary_format, n_t, weight)\u001b[0m\n\u001b[1;32m     62\u001b[0m fnc_weight_a, fnc_weight_s, fnc_weight_t \u001b[38;5;241m=\u001b[39m weight\n\u001b[1;32m     63\u001b[0m count_additions \u001b[38;5;241m=\u001b[39m fnc_weight_a(additions)\n\u001b[1;32m     64\u001b[0m count_substitutions \u001b[38;5;241m=\u001b[39m fnc_weight_s(substitutions,\n\u001b[0;32m---> 65\u001b[0m                                    \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mboundary_types\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     66\u001b[0m                                    \u001b[38;5;28mmin\u001b[39m(boundary_types))\n\u001b[1;32m     67\u001b[0m count_transpositions \u001b[38;5;241m=\u001b[39m fnc_weight_t(transpositions, n_t)\n\u001b[1;32m     68\u001b[0m count_edits \u001b[38;5;241m=\u001b[39m count_additions \u001b[38;5;241m+\u001b[39m count_substitutions \u001b[38;5;241m+\u001b[39m count_transpositions\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "# Convert the dataset to the format needed by segeval\n",
    "# https://github.com/cfournie/segmentation.evaluation/blob/master/segeval/agreement/__init__.py#L116\n",
    "# items_masses = {\n",
    "#     'item1' : {\n",
    "#         'coder1' : [5],\n",
    "#         'coder2' : [2,3],\n",
    "#         'coder2' : [1,1,3]\n",
    "#     },\n",
    "#     'item2' : {\n",
    "#         'coder1' : [8],\n",
    "#         'coder2' : [4,4],\n",
    "#         'coder2' : [2,2,4]\n",
    "#     }\n",
    "# }\n",
    "item_masses = {}\n",
    "for annotator in annotations.annotator.unique():\n",
    "    this_annotator_data = annotations[annotations.annotator == annotator]\n",
    "    for _, row in this_annotator_data.iterrows():\n",
    "        item_index = f\"{row.muni}-{row.session_id}\"\n",
    "        if item_index not in item_masses:\n",
    "            item_masses[item_index] = {}\n",
    "        \n",
    "        item_masses[item_index][annotator] = row[\"span_segmentation\"]\n",
    "\n",
    "# Compute boundary similarity\n",
    "segeval.actual_agreement_linear(item_masses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c01b21d-94f4-4798-b4ef-b46c56d0dac6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
