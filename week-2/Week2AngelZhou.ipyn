{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0e4c8e54e841838bd9a26cd5eddbc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching each model attached to event_ref:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d9300d250f46ca94b3d673c7929721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching transcripts:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting and storing each transcript as a CSV: 8it [00:09,  1.21s/it]\n"
     ]
    }
   ],
   "source": [
    "from cdp_data import CDPInstances, datasets\n",
    "\n",
    "# pull Long Beach data in Oct to Nov 2022\n",
    "long_beach_oct_nov_2022 = datasets.get_session_dataset(\n",
    "    CDPInstances.LongBeach,  # specify the city (or county) council we want data from\n",
    "    start_datetime=\"2022-10-01\",  # YYYY-MM-DD format\n",
    "    end_datetime=\"2022-11-01\",  # YYYY-MM-DD format\n",
    "    store_transcript=True,  # store transcripts locally for fast file reading\n",
    "    store_transcript_as_csv=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "session_datetime                                  2022-10-07 00:00:00+00:00\n",
       "session_index                                                             0\n",
       "session_content_hash      7a4115eaf950df5993f3e64bf792320bfcb9b21e9770a7...\n",
       "video_uri                 https://storage.googleapis.com/download/storag...\n",
       "video_start_time                                                       None\n",
       "video_end_time                                                         None\n",
       "caption_uri                                                            None\n",
       "external_source_id                                                     None\n",
       "id                                                             fe855a4e00b6\n",
       "key                                                    session/fe855a4e00b6\n",
       "event                     <cdp_backend.database.models.Event object at 0...\n",
       "transcript                <cdp_backend.database.models.Transcript object...\n",
       "transcript_path           /Users/angelzhou/Desktop/CDP_research/sig-cdp/...\n",
       "transcript_as_csv_path    /Users/angelzhou/Desktop/CDP_research/sig-cdp/...\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try with the 2nd meeting\n",
    "example_session = long_beach_oct_nov_2022.iloc[1]\n",
    "example_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>confidence</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>text</th>\n",
       "      <th>speaker_index</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.816301</td>\n",
       "      <td>362.2</td>\n",
       "      <td>363.5</td>\n",
       "      <td>Go ahead and get it started.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.869943</td>\n",
       "      <td>365.5</td>\n",
       "      <td>367.0</td>\n",
       "      <td>Good evening, everyone.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.869943</td>\n",
       "      <td>367.3</td>\n",
       "      <td>371.5</td>\n",
       "      <td>I'd like to go ahead and call this session of ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.869943</td>\n",
       "      <td>372.0</td>\n",
       "      <td>373.0</td>\n",
       "      <td>Can I get a roll call?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.869943</td>\n",
       "      <td>373.0</td>\n",
       "      <td>379.8</td>\n",
       "      <td>Please commence your templin here, commissione...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>1979</td>\n",
       "      <td>0.912839</td>\n",
       "      <td>12198.8</td>\n",
       "      <td>12199.2</td>\n",
       "      <td>Yeah.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>1980</td>\n",
       "      <td>0.912839</td>\n",
       "      <td>12200.6</td>\n",
       "      <td>12200.9</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.912839</td>\n",
       "      <td>12205.8</td>\n",
       "      <td>12206.7</td>\n",
       "      <td>Okay.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>1982</td>\n",
       "      <td>0.718904</td>\n",
       "      <td>12210.4</td>\n",
       "      <td>12210.8</td>\n",
       "      <td>Luscious.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1983</td>\n",
       "      <td>0.876675</td>\n",
       "      <td>12226.5</td>\n",
       "      <td>12230.9</td>\n",
       "      <td>These are find a reason to use my, I even fou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1984 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  confidence  start_time  end_time  \\\n",
       "0         0    0.816301       362.2     363.5   \n",
       "1         1    0.869943       365.5     367.0   \n",
       "2         2    0.869943       367.3     371.5   \n",
       "3         3    0.869943       372.0     373.0   \n",
       "4         4    0.869943       373.0     379.8   \n",
       "...     ...         ...         ...       ...   \n",
       "1979   1979    0.912839     12198.8   12199.2   \n",
       "1980   1980    0.912839     12200.6   12200.9   \n",
       "1981   1981    0.912839     12205.8   12206.7   \n",
       "1982   1982    0.718904     12210.4   12210.8   \n",
       "1983   1983    0.876675     12226.5   12230.9   \n",
       "\n",
       "                                                   text  speaker_index  \\\n",
       "0                          Go ahead and get it started.            NaN   \n",
       "1                               Good evening, everyone.            NaN   \n",
       "2     I'd like to go ahead and call this session of ...            NaN   \n",
       "3                                Can I get a roll call?            NaN   \n",
       "4     Please commence your templin here, commissione...            NaN   \n",
       "...                                                 ...            ...   \n",
       "1979                                              Yeah.            NaN   \n",
       "1980                                              Okay.            NaN   \n",
       "1981                                              Okay.            NaN   \n",
       "1982                                          Luscious.            NaN   \n",
       "1983   These are find a reason to use my, I even fou...            NaN   \n",
       "\n",
       "      speaker_name  annotations  \n",
       "0              NaN          NaN  \n",
       "1              NaN          NaN  \n",
       "2              NaN          NaN  \n",
       "3              NaN          NaN  \n",
       "4              NaN          NaN  \n",
       "...            ...          ...  \n",
       "1979           NaN          NaN  \n",
       "1980           NaN          NaN  \n",
       "1981           NaN          NaN  \n",
       "1982           NaN          NaN  \n",
       "1983           NaN          NaN  \n",
       "\n",
       "[1984 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "example_transcript_df = pd.read_csv(example_session.transcript_as_csv_path)\n",
    "example_transcript_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            Go ahead and get it started.\n",
       "1                                 Good evening, everyone.\n",
       "2       I'd like to go ahead and call this session of ...\n",
       "3                                  Can I get a roll call?\n",
       "4       Please commence your templin here, commissione...\n",
       "                              ...                        \n",
       "1979                                                Yeah.\n",
       "1980                                                Okay.\n",
       "1981                                                Okay.\n",
       "1982                                            Luscious.\n",
       "1983     These are find a reason to use my, I even fou...\n",
       "Name: text, Length: 1984, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_transcript_df[\"text\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One session with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>ner_model</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>named_entity_type</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1</td>\n",
       "      <td>TIME</td>\n",
       "      <td>evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2</td>\n",
       "      <td>ORG</td>\n",
       "      <td>the Planning Commission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>4</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Lewis Here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>8</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Vega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>8</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Rick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1967</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Fargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1967</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Quest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1969</td>\n",
       "      <td>GPE</td>\n",
       "      <td>Covina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1970</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Rick Saudi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1973</td>\n",
       "      <td>TIME</td>\n",
       "      <td>8:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1136 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id ner_model  sentence_index named_entity_type  \\\n",
       "0     fe855a4e00b6     spacy               1              TIME   \n",
       "1     fe855a4e00b6     spacy               2               ORG   \n",
       "2     fe855a4e00b6     spacy               4            PERSON   \n",
       "3     fe855a4e00b6     spacy               8            PERSON   \n",
       "4     fe855a4e00b6     spacy               8            PERSON   \n",
       "...            ...       ...             ...               ...   \n",
       "1131  fe855a4e00b6     spacy            1967               ORG   \n",
       "1132  fe855a4e00b6     spacy            1967               LOC   \n",
       "1133  fe855a4e00b6     spacy            1969               GPE   \n",
       "1134  fe855a4e00b6     spacy            1970            PERSON   \n",
       "1135  fe855a4e00b6     spacy            1973              TIME   \n",
       "\n",
       "                       entity  \n",
       "0                     evening  \n",
       "1     the Planning Commission  \n",
       "2                  Lewis Here  \n",
       "3                        Vega  \n",
       "4                        Rick  \n",
       "...                       ...  \n",
       "1131                    Fargo  \n",
       "1132                    Quest  \n",
       "1133                   Covina  \n",
       "1134               Rick Saudi  \n",
       "1135                     8:21  \n",
       "\n",
       "[1136 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "res_df = pd.DataFrame()\n",
    "# Process first sentence in the text column\n",
    "for i in range(0,example_transcript_df[\"text\"].size):\n",
    "    doc = nlp(example_transcript_df[\"text\"][i])\n",
    "    ent_text = []\n",
    "    ent_lab = []\n",
    "    # Find named entities, phrases and concepts\n",
    "    for entity in doc.ents:\n",
    "        ent_text.append(entity.text)\n",
    "        ent_lab.append(entity.label_)\n",
    "    # print(ent_text, ent_lab)\n",
    "    num_ent = len(ent_lab)\n",
    "    temp_df = pd.DataFrame({'session_id': np.repeat(example_session[\"id\"],num_ent),\n",
    "        'ner_model': np.repeat(\"spacy\", num_ent),\n",
    "        'sentence_index': np.repeat(i, num_ent),\n",
    "        'named_entity_type': ent_lab,\n",
    "        'entity': ent_text})\n",
    "    res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spacy function\n",
    "def spacy_fun(example_transcript_df, res_df):\n",
    "    # Load English tokenizer, tagger, parser and NER\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    # res_df = pd.DataFrame()\n",
    "    # Process each sentence in the text column\n",
    "    for i in range(0,example_transcript_df[\"text\"].size):\n",
    "        doc = nlp(example_transcript_df[\"text\"][i])\n",
    "        ent_text = []\n",
    "        ent_lab = []\n",
    "        # Find named entities, phrases and concepts\n",
    "        for entity in doc.ents:\n",
    "            ent_text.append(entity.text)\n",
    "            ent_lab.append(entity.label_)\n",
    "        # print(ent_text, ent_lab)\n",
    "        num_ent = len(ent_lab)\n",
    "        temp_df = pd.DataFrame({'session_id': np.repeat(example_session[\"id\"],num_ent),\n",
    "            'ner_model': np.repeat(\"spacy\", num_ent),\n",
    "            'sentence_index': np.repeat(i, num_ent),\n",
    "            'named_entity_type': ent_lab,\n",
    "            'entity': ent_text})\n",
    "        res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame()\n",
    "for i in range(0,len(long_beach_oct_nov_2022)):\n",
    "    session = long_beach_oct_nov_2022.iloc[i]\n",
    "    example_transcript_df = pd.read_csv(session.transcript_as_csv_path)\n",
    "    res_df = spacy_fun(example_transcript_df, res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>ner_model</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>named_entity_type</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Commission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>1</td>\n",
       "      <td>TIME</td>\n",
       "      <td>60 4 p.m.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2</td>\n",
       "      <td>CARDINAL</td>\n",
       "      <td>three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2</td>\n",
       "      <td>DATE</td>\n",
       "      <td>today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Camacho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2366</td>\n",
       "      <td>PRODUCT</td>\n",
       "      <td>Lagoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5458</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2367</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Marina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5459</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2369</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Sundar Studios</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5460</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2369</td>\n",
       "      <td>ORG</td>\n",
       "      <td>ABC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5461</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>spacy</td>\n",
       "      <td>2372</td>\n",
       "      <td>TIME</td>\n",
       "      <td>a good night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5462 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id ner_model  sentence_index named_entity_type          entity\n",
       "0     fe855a4e00b6     spacy               1               ORG      Commission\n",
       "1     fe855a4e00b6     spacy               1              TIME       60 4 p.m.\n",
       "2     fe855a4e00b6     spacy               2          CARDINAL           three\n",
       "3     fe855a4e00b6     spacy               2              DATE           today\n",
       "4     fe855a4e00b6     spacy               2               ORG         Camacho\n",
       "...            ...       ...             ...               ...             ...\n",
       "5457  fe855a4e00b6     spacy            2366           PRODUCT          Lagoon\n",
       "5458  fe855a4e00b6     spacy            2367               LOC          Marina\n",
       "5459  fe855a4e00b6     spacy            2369            PERSON  Sundar Studios\n",
       "5460  fe855a4e00b6     spacy            2369               ORG             ABC\n",
       "5461  fe855a4e00b6     spacy            2372              TIME    a good night\n",
       "\n",
       "[5462 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One session with transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>ner_model</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>named_entity_type</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>Planning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>2</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>Commission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>4</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>Lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>4</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>Here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>4</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>Fargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>1969</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>Castillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>1969</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>reduce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>1969</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>Co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>1969</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>##vina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>transformers</td>\n",
       "      <td>1970</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>Rick</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1138 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        session_id     ner_model  sentence_index named_entity_type      entity\n",
       "0     fe855a4e00b6  transformers               2             B-ORG    Planning\n",
       "1     fe855a4e00b6  transformers               2             I-ORG  Commission\n",
       "2     fe855a4e00b6  transformers               4             B-PER       Lewis\n",
       "3     fe855a4e00b6  transformers               4             I-PER        Here\n",
       "4     fe855a4e00b6  transformers               4             B-ORG       Fargo\n",
       "...            ...           ...             ...               ...         ...\n",
       "1133  fe855a4e00b6  transformers            1969             B-PER    Castillo\n",
       "1134  fe855a4e00b6  transformers            1969             B-PER      reduce\n",
       "1135  fe855a4e00b6  transformers            1969             B-PER          Co\n",
       "1136  fe855a4e00b6  transformers            1969             B-PER      ##vina\n",
       "1137  fe855a4e00b6  transformers            1970             B-PER        Rick\n",
       "\n",
       "[1138 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "# example = \"My name is Wolfgang and I live in Berlin\"\n",
    "res_df = pd.DataFrame()\n",
    "# Process first sentence in the text column\n",
    "for i in range(0,example_transcript_df[\"text\"].size):\n",
    "    ner_results = nlp(example_transcript_df[\"text\"][i])\n",
    "    # print(ner_results)\n",
    "    ent_text = []\n",
    "    ent_lab = []\n",
    "    for entity in ner_results:\n",
    "            ent_text.append(entity[\"word\"])\n",
    "            ent_lab.append(entity[\"entity\"])\n",
    "    num_ent = len(ent_lab)\n",
    "    temp_df = pd.DataFrame({'session_id': np.repeat(example_session[\"id\"],num_ent),\n",
    "        'ner_model': np.repeat(\"transformers\", num_ent),\n",
    "        'sentence_index': np.repeat(i, num_ent),\n",
    "        'named_entity_type': ent_lab,\n",
    "        'entity': ent_text})\n",
    "    res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer function\n",
    "def transformer_fun(example_transcript_df, res_df):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")\n",
    "\n",
    "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    # example = \"My name is Wolfgang and I live in Berlin\"\n",
    "    # res_df = pd.DataFrame()\n",
    "    # Process first sentence in the text column\n",
    "    for i in range(0,example_transcript_df[\"text\"].size):\n",
    "        ner_results = nlp(example_transcript_df[\"text\"][i])\n",
    "        # print(ner_results)\n",
    "        ent_text = []\n",
    "        ent_lab = []\n",
    "        for entity in ner_results:\n",
    "                ent_text.append(entity[\"word\"])\n",
    "                ent_lab.append(entity[\"entity\"])\n",
    "        num_ent = len(ent_lab)\n",
    "        temp_df = pd.DataFrame({'session_id': np.repeat(example_session[\"id\"],num_ent),\n",
    "            'ner_model': np.repeat(\"transformers\", num_ent),\n",
    "            'sentence_index': np.repeat(i, num_ent),\n",
    "            'named_entity_type': ent_lab,\n",
    "            'entity': ent_text})\n",
    "        res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "    return res_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One session with flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sig-cdp/lib/python3.9/site-packages/huggingface_hub/file_download.py:594: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:51:41,307 loading file /Users/angelzhou/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
      "2023-01-20 09:51:44,303 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>ner_model</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>named_entity_type</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>2</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Planning Commission</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>4</td>\n",
       "      <td>PER</td>\n",
       "      <td>Lewis Here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>4</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Fargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>5</td>\n",
       "      <td>PER</td>\n",
       "      <td>Quest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>8</td>\n",
       "      <td>PER</td>\n",
       "      <td>Castillo Vice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>1967</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Fargo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>1967</td>\n",
       "      <td>PER</td>\n",
       "      <td>Quest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>1969</td>\n",
       "      <td>PER</td>\n",
       "      <td>Castillo Vice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>1969</td>\n",
       "      <td>PER</td>\n",
       "      <td>Covina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>1970</td>\n",
       "      <td>PER</td>\n",
       "      <td>Rick Saudi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       session_id ner_model  sentence_index named_entity_type  \\\n",
       "0    fe855a4e00b6     flair               2               ORG   \n",
       "1    fe855a4e00b6     flair               4               PER   \n",
       "2    fe855a4e00b6     flair               4               ORG   \n",
       "3    fe855a4e00b6     flair               5               PER   \n",
       "4    fe855a4e00b6     flair               8               PER   \n",
       "..            ...       ...             ...               ...   \n",
       "512  fe855a4e00b6     flair            1967               LOC   \n",
       "513  fe855a4e00b6     flair            1967               PER   \n",
       "514  fe855a4e00b6     flair            1969               PER   \n",
       "515  fe855a4e00b6     flair            1969               PER   \n",
       "516  fe855a4e00b6     flair            1970               PER   \n",
       "\n",
       "                  entity  \n",
       "0    Planning Commission  \n",
       "1             Lewis Here  \n",
       "2                  Fargo  \n",
       "3                  Quest  \n",
       "4          Castillo Vice  \n",
       "..                   ...  \n",
       "512                Fargo  \n",
       "513                Quest  \n",
       "514        Castillo Vice  \n",
       "515               Covina  \n",
       "516           Rick Saudi  \n",
       "\n",
       "[517 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "res_df = pd.DataFrame()\n",
    "# load the NER tagger\n",
    "tagger = SequenceTagger.load('ner')\n",
    "for i in range(0,example_transcript_df[\"text\"].size):\n",
    "    # make a sentence\n",
    "    sentence = Sentence(example_transcript_df[\"text\"][i])\n",
    "    \n",
    "    # run NER over sentence\n",
    "    tagger.predict(sentence)\n",
    "    # ner_results = nlp(example_transcript_df[\"text\"][5])\n",
    "    # print(ner_results)\n",
    "    ent_text = []\n",
    "    ent_lab = []\n",
    "    for entity in sentence.get_spans('ner'):\n",
    "            ent_text.append(entity.text)\n",
    "            ent_lab.append(entity.get_label(\"ner\").value)\n",
    "    num_ent = len(ent_lab)\n",
    "    temp_df = pd.DataFrame({'session_id': np.repeat(example_session[\"id\"],num_ent),\n",
    "        'ner_model': np.repeat(\"flair\", num_ent),\n",
    "        'sentence_index': np.repeat(i, num_ent),\n",
    "        'named_entity_type': ent_lab,\n",
    "        'entity': ent_text})\n",
    "    res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning Commission\n",
      "ORG\n"
     ]
    }
   ],
   "source": [
    "# iterate over entities and print each\n",
    "for entity in sentence.get_spans('ner'):\n",
    "    print(entity.text)\n",
    "    print(entity.get_label(\"ner\").value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/sig-cdp/lib/python3.9/site-packages/huggingface_hub/file_download.py:594: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-20 09:47:07,278 loading file /Users/angelzhou/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
      "2023-01-20 09:47:09,292 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>ner_model</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>named_entity_type</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fe855a4e00b6</td>\n",
       "      <td>flair</td>\n",
       "      <td>2</td>\n",
       "      <td>ORG</td>\n",
       "      <td>Planning Commission</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     session_id ner_model  sentence_index named_entity_type  \\\n",
       "0  fe855a4e00b6     flair               2               ORG   \n",
       "\n",
       "                entity  \n",
       "0  Planning Commission  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df = pd.DataFrame()\n",
    "# make a sentence\n",
    "sentence = Sentence(example_transcript_df[\"text\"][2])\n",
    "# load the NER tagger\n",
    "tagger = SequenceTagger.load('ner')\n",
    "# run NER over sentence\n",
    "tagger.predict(sentence)\n",
    "# ner_results = nlp(example_transcript_df[\"text\"][5])\n",
    "# print(ner_results)\n",
    "ent_text = []\n",
    "ent_lab = []\n",
    "for entity in sentence.get_spans('ner'):\n",
    "        ent_text.append(entity.text)\n",
    "        ent_lab.append(entity.get_label(\"ner\").value)\n",
    "num_ent = len(ent_lab)\n",
    "temp_df = pd.DataFrame({'session_id': np.repeat(example_session[\"id\"],num_ent),\n",
    "    'ner_model': np.repeat(\"flair\", num_ent),\n",
    "    'sentence_index': np.repeat(2, num_ent),\n",
    "    'named_entity_type': ent_lab,\n",
    "    'entity': ent_text})\n",
    "res_df = pd.concat([res_df, temp_df], ignore_index=True)\n",
    "res_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1:\n",
    "### What types of entities are recognized over all the meetings? I.e. How many are people? How many are organizations? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session_id</th>\n",
       "      <th>ner_model</th>\n",
       "      <th>sentence_index</th>\n",
       "      <th>named_entity_type</th>\n",
       "      <th>entity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [session_id, ner_model, sentence_index, named_entity_type, entity]\n",
       "Index: []"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "### What meetings have more or less entities recognized overall? We want to see the distribution of entities mentioned over different meetings. I.e. Meeting abcd1234 had 204 recognized entities, meeting efgh5678 had 559 recognized entities, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'B-PER', 'score': 0.9990139, 'index': 4, 'word': 'Wolfgang', 'start': 11, 'end': 19}, {'entity': 'B-LOC', 'score': 0.999645, 'index': 9, 'word': 'Berlin', 'start': 34, 'end': 40}]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "### Make a third plot that is entirely up to you. Come up with a question and try to answer it via a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-PER'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wolfgang'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sig-cdp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "866550a171a37d04fa390dd1d3723300541a1ed2312f7ca538392a16539193a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
